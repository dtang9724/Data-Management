{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Module 5 In-Class Assignment\n",
    "Python for Data Analytics \n",
    "<br>Professor James Ng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <b>This assignment is due by THURSDAY, DEC 12 at 11:59PM.</b> \n",
    "    <br>Late submissions will NOT be graded. \n",
    "    <br>\n",
    "    <br>Remember to save and submit frequently!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Scraping university websites for email addresses of department heads\n",
    "\n",
    "Suppose you want to get the email addresses of all the department heads from US universities. Suppose you need these emails so that you can send all of them a survey. You could of course do this manually, but with hundreds of websites, that will be too labor intensive. (*Instructor note: This was part of an actual project my team and I worked on.*)\n",
    "\n",
    "For this final in-class assignment, you will do some simple web scraping. You will be scraping email addresses from four university websites given in the csv file below. Please see the section on IMPORTANT INSTRUCTIONS AND HINTS below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTANT INSTRUCTIONS AND HINTS\n",
    "* Your final product should be a DataFrame that looks like this (showing the first ten rows):\n",
    "\n",
    "![Image of first ten rows of results](https://www3.nd.edu/~jng2/df_emails_head10.png)\n",
    "\n",
    "* That is, you only need to populate two columns: one for email addresses, and the another that simply stores the URL of the website that an email address came from. Do not spend time scraping anything else.\n",
    "\n",
    "* Your final DataFrame should have **231 rows** and, as mentioned above, the two columns. Watch out for duplicate entries.\n",
    "\n",
    "* `pandas`, `BeautifulSoup` and `requests` are all you need for this assignment. I strongly discourage you from using anything else.\n",
    "\n",
    "* Because all I am asking for are email addresses, code that you write for one website should also work without any trouble on the other websites. Therefore, pick one website and write and test your code on it. Once your code works well on that website, it should work equally well on the other three.\n",
    "* There may be some irrelevant email addresses, such as webmaster@website.com. Do not spend time trying to detect and remove them; just leave them in your final DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# SETUP. RUN BUT DO NOT CHANGE. \n",
    "# These should be all the packages you need for this assignment.\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "# The csv file below contains the four websites to scrape. \n",
    "websites = pd.read_csv(\"http://www3.nd.edu/~jng2/dept_urls_small.csv\")\n",
    "websites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
